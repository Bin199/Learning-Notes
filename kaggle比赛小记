kaggle泰坦尼克号生还人数比赛：

考虑到的特征有很多，把各个特征与结果(survial)的分布图画出来，去选择几个重要的特征。

数据的处理比较繁杂但是不难

模型就直接使用api用了几个常用的模型，有随机森林，朴素贝叶斯等等

kaggle比赛他人经验总结：
1.作者：匿名用户
链接：https://www.zhihu.com/question/24533374/answer/34602798

参加过几次，只拿过几个前10%，匿了。下面是我的一些个人经验：1. 一定做Ensemble，甚至是对submissions做ensemble。
2. 目的如果单纯是拿好的排名，那么就找人多的比赛参加，因为那些参加人数上千的比赛里面大批僵尸参赛者，超过他们就可以进25%了。
3. 对大多数比赛来说，Feature Engineering比选用什么模型更重要
4. 多看论坛，大家会在比赛进行中讨论很多泛泛的思路，对自己可能有帮助。有时候会有人发布比较好的Beat the benchmark代码，
仔细思考为什么这个模型能够work，在上面涂涂改改有时候效果更好。5. 永远相信自己的cross validation结果，甚于public leaderboard，
结束前后的榜单常常震动巨大，具体例子参见 Description - Africa Soil Property Prediction Challenge 和
Description - Higgs Boson Machine Learning Challenge6. 每次比赛最有价值的东西就是结束之后的方法分享帖，
大家的方法都很不一样，挑一个说得比较全面清晰的方法，自己尝试重现一个一样或者接近的效果，然后再尝试改进它，这个过程能学到非常多东西。

2.作者：Naiyan Wang
链接：https://www.zhihu.com/question/24533374/answer/34631808

先贴下Kaggle Profile以示诚意：Winsty | Kaggle 我是KDD Cup专业户，虽然每年做的都不是特别好。。。
和一些Kaggle专业户们无论从数量还是质量上都差了好多。不过我一直觉得Kaggle在我PhD期间扮演了一个非常重要的角色。
下面列几个我觉得比较重要的问题自问自答下哈Kaggle的比赛究竟锻炼的是什么能力？首先说，绝大部分的Kaggle比赛是Data Mining(DM)比赛
（除少数是和Discrete Optimization还有Computer Vision(CV) 有关），最重要的是和Machine Learning(ML)关系不大。
这是很多人一个误区，往往希望在Kaggle上学到很多ML的知识。Kaggle教给我的第一件事情，就是让我清晰领会到了这两者之间的不同：
ML一般从模型或者算法出发，讲的是模型或者算法本身存在的不合理的地方，然后提出新的假设，从而去优化模型或算法。
在这个过程中并不针对某一个具体的特殊的问题。而DM恰恰相反，它是从数据本身问题本身出发，希望针对问题的特性来设计最适合的方案。
关键是在于对问题和数据的理解。之前总是觉得，DM/CV的paper都好水，到处找一个应用套。在我想明白这个问题之后，我就开始懂得欣赏DM/CV的paper。
其次，我觉得在一个DM的比赛中，最能锻炼到的是对于数据的"嗅觉"。举一个最有趣的例子，往往在比赛中会存在Data Leakage的情况，也就是说，
某些和label相关的信息不小心会泄漏在feature中。有人通过这样的feature取得了很好的成绩之后，往往有人觉得非常鄙视。
当然我不是说Data Leakage是一件好事情，但是在这背后往往隐藏的是发现leakage的人对于数据本身深刻的认识。这并不是每个人都能做到的。
换句话讲，就算没有leakage，这群人还是会排名很前。在Kaggle的比赛中，能收获最大的就是这种嗅觉。这其实也把我自己训练成了一个data believer：
也许一次两次的巧合真的是意外，但是如果巧合总是持续发生，那么背后一定有一个原因。怎样才能做好Kaggle的比赛？第一点也是最重要的一点就是专注，
专注，再专注。其实说来惭愧，我在这点上做得很不好。第一年开始高歌猛进了一段，中间卡住，也是能力不足，然后就放弃了。第二年抱学长大腿侥幸成绩不错，
其实个人来讲没有做出太大贡献。先是去写了一个NIPS，然后又去处理了一些私事。第三年做到一半，很偶然地被拉去百度做了ImageNet的比赛，精力主要就放到了ImageNet上。
坑了队友。。。所以其实这三年，离我自己的期待都有一定的距离，我也很清楚问题出在哪里。希望明年能真正focus一次吧。第二点，永远不要放弃。希望总存在于绝望之后。
每个比赛都会有一个瓶颈期。耐心地去突破它后，就是一片开阔天空。第三点，切记只看不做。很多人只喜欢纸上谈兵，武断觉得这个问题，或者这个数据就应该是怎样。
很多数据的特质都是要真正动手做进去才能发现其中的奥妙，针对这些特质设计的一些Feature或者Model，往往都能带来极大的提高。
第四点，才是多看，尤其是在比赛结束之后。很多leader会在比赛结束之后部分甚至全部地公布自己的解法。
这个时候返回去看看在比赛中自己忽略掉了什么地方，才是成长最最重要的。第一年的比赛教给了我在一个实际的推荐系统里session的重要性。
第二年的比赛教给了我机器不是万能的，人肉一些规则往往更有效。每一年其实都对实际的Data Mining问题有新的认识，也更清楚了哪些paper是真的work，
哪些是在灌水。这其实也就是我来做比赛的最大目的吧。技术方面上什么最关键？前面提到Kaggle主要是以Data Mining的比赛为主，那么这个答案就非常直接了：
Feature Engineering  无数经验告诉我们，做Kaggle比赛如果是抱着Machine Learning的态度，沉迷于facny的模型而忽略数据本身，一定会死得很惨很惨！
当然，基本的ML知识还是有的。在比赛中，最常用的分类器一般是Gradient Boosting Tree(GBDT)和Random Forest（对，你没看错，
不是那个在教科书中推Dual时让很多人痛不欲生的SVM）一些常见的预处理技巧，比如PCA，KMeans，TF/IDF，Hashing等等都还是必须的。
这里就不展开讲了。最后，但是非常关键的一点是Ensemble 从KDD Cup到Imagenet，我从来没见过ensemble不会改善结果的情况，只是多与少的问题。
不做ensemble就意味着你自己告别了一大块宝藏。总结我觉得Kaggle是一个对于每个想成为所谓的Data Scientist的同学最好的试炼厂。
在这里，你就会知道课上学到的那些东西和能解决一个实际问题所需要的能力的差距。更何况，在学校里往往是拿不到任何大规模的数据。
绝大多数课堂上用的还是只有几百个几千个数据的UCI dataset。Kaggle是缩小这个gap最好的一个地方。最后，希望大家在Kaggle上都玩得愉快~~
